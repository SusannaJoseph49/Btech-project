{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from catboost import CatBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 10160\n",
      "Testing set size: 2541\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Load and preprocess the dataset\n",
    "df = pd.read_csv('combined_data.csv')\n",
    "\n",
    "# Replace infinite values with NaN and drop rows with NaN values\n",
    "df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "df = df.dropna()\n",
    "\n",
    "# Drop rows with missing target values\n",
    "df = df.dropna(subset=['Cell_Type'])\n",
    "\n",
    "# Encode target variable\n",
    "label_encoder = LabelEncoder()\n",
    "df['Cell_Type'] = label_encoder.fit_transform(df['Cell_Type'])\n",
    "\n",
    "# Split the data into features and target variable\n",
    "X = df.drop('Cell_Type', axis=1)\n",
    "y = df['Cell_Type']  # Target is encoded\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Feature scaling (optional for some models)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Verify the separation\n",
    "print(f\"Training set size: {X_train.shape[0]}\")\n",
    "print(f\"Testing set size: {X_test.shape[0]}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Create the base models and the Voting Classifier\n",
    "base_models = [\n",
    "    ('catboost', CatBoostClassifier(verbose=0)),  # Initial placeholder parameters\n",
    "    ('xgboost', XGBClassifier(use_label_encoder=False, eval_metric='mlogloss')),\n",
    "    ('lgbm', LGBMClassifier())\n",
    "]\n",
    "\n",
    "# Create the voting model with soft voting\n",
    "voting_model = VotingClassifier(estimators=base_models, voting='soft')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1728 candidates, totalling 8640 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/susan/BTP/.venv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [10:38:04] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/susan/BTP/.venv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [10:38:04] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/susan/BTP/.venv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [10:38:04] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/susan/BTP/.venv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [10:38:04] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/susan/BTP/.venv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [10:38:04] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/susan/BTP/.venv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [10:38:04] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/susan/BTP/.venv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [10:38:04] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/susan/BTP/.venv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [10:38:04] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4673, number of negative: 3455\n",
      "[LightGBM] [Info] Number of positive: 4673, number of negative: 3455\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003958 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3570\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004427 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3570\n",
      "[LightGBM] [Info] Number of data points in the train set: 8128, number of used features: 14\n",
      "[LightGBM] [Info] Number of data points in the train set: 8128, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.574926 -> initscore=0.301979\n",
      "[LightGBM] [Info] Start training from score 0.301979\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.574926 -> initscore=0.301979\n",
      "[LightGBM] [Info] Start training from score 0.301979\n",
      "[LightGBM] [Info] Number of positive: 4673, number of negative: 3455\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001448 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3570\n",
      "[LightGBM] [Info] Number of data points in the train set: 8128, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.574926 -> initscore=0.301979\n",
      "[LightGBM] [Info] Number of positive: 4672, number of negative: 3456[LightGBM] [Info] Start training from score 0.301979\n",
      "\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004962 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3570\n",
      "[LightGBM] [Info] Number of data points in the train set: 8128, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.574803 -> initscore=0.301475\n",
      "[LightGBM] [Info] Start training from score 0.301475\n",
      "[LightGBM] [Info] Number of positive: 4673, number of negative: 3455\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003425 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3570\n",
      "[LightGBM] [Info] Number of data points in the train set: 8128, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.574926 -> initscore=0.301979\n",
      "[LightGBM] [Info] Start training from score 0.301979\n",
      "[LightGBM] [Info] Number of positive: 4673, number of negative: 3455\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000994 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3570\n",
      "[LightGBM] [Info] Number of data points in the train set: 8128, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.574926 -> initscore=0.301979\n",
      "[LightGBM] [Info] Start training from score 0.301979\n",
      "[LightGBM] [Info] Number of positive: 4672, number of negative: 3456\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000715 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3570\n",
      "[LightGBM] [Info] Number of data points in the train set: 8128, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.574803 -> initscore=0.301475\n",
      "[LightGBM] [Info] Start training from score 0.301475\n",
      "[LightGBM] [Info] Number of positive: 4673, number of negative: 3455\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000872 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3570\n",
      "[LightGBM] [Info] Number of data points in the train set: 8128, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.574926 -> initscore=0.301979\n",
      "[LightGBM] [Info] Start training from score 0.301979\n",
      "[CV] END catboost__depth=4, catboost__iterations=500, catboost__learning_rate=0.01, lgbm__learning_rate=0.01, lgbm__n_estimators=100, lgbm__num_leaves=31, xgboost__learning_rate=0.01, xgboost__max_depth=3, xgboost__n_estimators=100; total time=   7.1s\n",
      "[CV] END catboost__depth=4, catboost__iterations=500, catboost__learning_rate=0.01, lgbm__learning_rate=0.01, lgbm__n_estimators=100, lgbm__num_leaves=31, xgboost__learning_rate=0.01, xgboost__max_depth=3, xgboost__n_estimators=100; total time=   7.1s\n",
      "[CV] END catboost__depth=4, catboost__iterations=500, catboost__learning_rate=0.01, lgbm__learning_rate=0.01, lgbm__n_estimators=100, lgbm__num_leaves=31, xgboost__learning_rate=0.01, xgboost__max_depth=3, xgboost__n_estimators=100; total time=   7.2s\n",
      "[CV] END catboost__depth=4, catboost__iterations=500, catboost__learning_rate=0.01, lgbm__learning_rate=0.01, lgbm__n_estimators=100, lgbm__num_leaves=31, xgboost__learning_rate=0.01, xgboost__max_depth=3, xgboost__n_estimators=100; total time=   7.9s\n",
      "[CV] END catboost__depth=4, catboost__iterations=500, catboost__learning_rate=0.01, lgbm__learning_rate=0.01, lgbm__n_estimators=100, lgbm__num_leaves=31, xgboost__learning_rate=0.01, xgboost__max_depth=3, xgboost__n_estimators=100; total time=   8.1s\n",
      "[CV] END catboost__depth=4, catboost__iterations=500, catboost__learning_rate=0.01, lgbm__learning_rate=0.01, lgbm__n_estimators=100, lgbm__num_leaves=31, xgboost__learning_rate=0.01, xgboost__max_depth=3, xgboost__n_estimators=500; total time=   8.2s\n",
      "[CV] END catboost__depth=4, catboost__iterations=500, catboost__learning_rate=0.01, lgbm__learning_rate=0.01, lgbm__n_estimators=100, lgbm__num_leaves=31, xgboost__learning_rate=0.01, xgboost__max_depth=3, xgboost__n_estimators=500; total time=   8.3s\n",
      "[CV] END catboost__depth=4, catboost__iterations=500, catboost__learning_rate=0.01, lgbm__learning_rate=0.01, lgbm__n_estimators=100, lgbm__num_leaves=31, xgboost__learning_rate=0.01, xgboost__max_depth=3, xgboost__n_estimators=500; total time=   8.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/susan/BTP/.venv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [10:38:12] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/susan/BTP/.venv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [10:38:12] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/susan/BTP/.venv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [10:38:12] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/susan/BTP/.venv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [10:38:13] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/susan/BTP/.venv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [10:38:13] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/susan/BTP/.venv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [10:38:13] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/susan/BTP/.venv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [10:38:13] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/susan/BTP/.venv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [10:38:13] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4673, number of negative: 3455\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014892 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3570\n",
      "[LightGBM] [Info] Number of data points in the train set: 8128, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.574926 -> initscore=0.301979\n",
      "[LightGBM] [Info] Start training from score 0.301979\n",
      "[LightGBM] [Info] Number of positive: 4673, number of negative: 3455\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001651 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3570\n",
      "[LightGBM] [Info] Number of data points in the train set: 8128, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.574926 -> initscore=0.301979\n",
      "[LightGBM] [Info] Start training from score 0.301979\n",
      "[LightGBM] [Info] Number of positive: 4672, number of negative: 3456\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001065 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3570\n",
      "[LightGBM] [Info] Number of data points in the train set: 8128, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.574803 -> initscore=0.301475\n",
      "[LightGBM] [Info] Start training from score 0.301475\n",
      "[LightGBM] [Info] Number of positive: 4673, number of negative: 3455\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014486 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3570\n",
      "[LightGBM] [Info] Number of data points in the train set: 8128, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.574926 -> initscore=0.301979\n",
      "[LightGBM] [Info] Start training from score 0.301979\n",
      "[LightGBM] [Info] Number of positive: 4673, number of negative: 3455\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001931 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3570\n",
      "[LightGBM] [Info] Number of data points in the train set: 8128, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.574926 -> initscore=0.301979\n",
      "[LightGBM] [Info] Start training from score 0.301979\n",
      "[LightGBM] [Info] Number of positive: 4673, number of negative: 3455\n",
      "[LightGBM] [Info] Number of positive: 4673, number of negative: 3455[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007199 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "\n",
      "[LightGBM] [Info] Total Bins 3570\n",
      "[LightGBM] [Info] Number of data points in the train set: 8128, number of used features: 14\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003909 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3570\n",
      "[LightGBM] [Info] Number of data points in the train set: 8128, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.574926 -> initscore=0.301979\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.574926 -> initscore=0.301979\n",
      "[LightGBM] [Info] Start training from score 0.301979\n",
      "[LightGBM] [Info] Start training from score 0.301979\n",
      "[CV] END catboost__depth=4, catboost__iterations=500, catboost__learning_rate=0.01, lgbm__learning_rate=0.01, lgbm__n_estimators=100, lgbm__num_leaves=31, xgboost__learning_rate=0.01, xgboost__max_depth=3, xgboost__n_estimators=500; total time=   8.0s\n",
      "[CV] END catboost__depth=4, catboost__iterations=500, catboost__learning_rate=0.01, lgbm__learning_rate=0.01, lgbm__n_estimators=100, lgbm__num_leaves=31, xgboost__learning_rate=0.01, xgboost__max_depth=6, xgboost__n_estimators=100; total time=   7.0s\n",
      "[CV] END catboost__depth=4, catboost__iterations=500, catboost__learning_rate=0.01, lgbm__learning_rate=0.01, lgbm__n_estimators=100, lgbm__num_leaves=31, xgboost__learning_rate=0.01, xgboost__max_depth=6, xgboost__n_estimators=100; total time=   8.7s\n",
      "[CV] END catboost__depth=4, catboost__iterations=500, catboost__learning_rate=0.01, lgbm__learning_rate=0.01, lgbm__n_estimators=100, lgbm__num_leaves=31, xgboost__learning_rate=0.01, xgboost__max_depth=3, xgboost__n_estimators=500; total time=   9.8s\n",
      "[CV] END catboost__depth=4, catboost__iterations=500, catboost__learning_rate=0.01, lgbm__learning_rate=0.01, lgbm__n_estimators=100, lgbm__num_leaves=31, xgboost__learning_rate=0.01, xgboost__max_depth=6, xgboost__n_estimators=100; total time=   8.7s\n",
      "[CV] END catboost__depth=4, catboost__iterations=500, catboost__learning_rate=0.01, lgbm__learning_rate=0.01, lgbm__n_estimators=100, lgbm__num_leaves=31, xgboost__learning_rate=0.01, xgboost__max_depth=6, xgboost__n_estimators=100; total time=   9.0s\n",
      "[CV] END catboost__depth=4, catboost__iterations=500, catboost__learning_rate=0.01, lgbm__learning_rate=0.01, lgbm__n_estimators=100, lgbm__num_leaves=31, xgboost__learning_rate=0.01, xgboost__max_depth=6, xgboost__n_estimators=100; total time=   9.3s\n",
      "[LightGBM] [Info] Number of positive: 4672, number of negative: 3456\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001944 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3570\n",
      "[LightGBM] [Info] Number of data points in the train set: 8128, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.574803 -> initscore=0.301475\n",
      "[LightGBM] [Info] Start training from score 0.301475\n",
      "[CV] END catboost__depth=4, catboost__iterations=500, catboost__learning_rate=0.01, lgbm__learning_rate=0.01, lgbm__n_estimators=100, lgbm__num_leaves=31, xgboost__learning_rate=0.01, xgboost__max_depth=6, xgboost__n_estimators=500; total time=  10.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/susan/BTP/.venv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [10:38:21] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/susan/BTP/.venv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [10:38:21] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/susan/BTP/.venv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [10:38:21] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/susan/BTP/.venv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [10:38:22] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/susan/BTP/.venv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [10:38:22] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/susan/BTP/.venv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [10:38:23] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/susan/BTP/.venv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [10:38:23] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4673, number of negative: 3455\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002121 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3570\n",
      "[LightGBM] [Info] Number of data points in the train set: 8128, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.574926 -> initscore=0.301979\n",
      "[LightGBM] [Info] Start training from score 0.301979\n",
      "[LightGBM] [Info] Number of positive: 4672, number of negative: 3456\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002679 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3570\n",
      "[LightGBM] [Info] Number of data points in the train set: 8128, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.574803 -> initscore=0.301475\n",
      "[LightGBM] [Info] Start training from score 0.301475\n",
      "[LightGBM] [Info] Number of positive: 4673, number of negative: 3455\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008529 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3570\n",
      "[LightGBM] [Info] Number of data points in the train set: 8128, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.574926 -> initscore=0.301979\n",
      "[LightGBM] [Info] Start training from score 0.301979\n",
      "[LightGBM] [Info] Number of positive: 4673, number of negative: 3455\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005179 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3570\n",
      "[LightGBM] [Info] Number of data points in the train set: 8128, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.574926 -> initscore=0.301979\n",
      "[LightGBM] [Info] Start training from score 0.301979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/susan/BTP/.venv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [10:38:24] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4673, number of negative: 3455\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004026 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3570\n",
      "[LightGBM] [Info] Number of data points in the train set: 8128, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.574926 -> initscore=0.301979\n",
      "[LightGBM] [Info] Start training from score 0.301979\n",
      "[LightGBM] [Info] Number of positive: 4673, number of negative: 3455\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001536 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3570\n",
      "[LightGBM] [Info] Number of data points in the train set: 8128, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.574926 -> initscore=0.301979\n",
      "[LightGBM] [Info] Start training from score 0.301979\n",
      "[CV] END catboost__depth=4, catboost__iterations=500, catboost__learning_rate=0.01, lgbm__learning_rate=0.01, lgbm__n_estimators=100, lgbm__num_leaves=31, xgboost__learning_rate=0.01, xgboost__max_depth=6, xgboost__n_estimators=500; total time=  10.4s\n",
      "[CV] END catboost__depth=4, catboost__iterations=500, catboost__learning_rate=0.01, lgbm__learning_rate=0.01, lgbm__n_estimators=100, lgbm__num_leaves=31, xgboost__learning_rate=0.01, xgboost__max_depth=9, xgboost__n_estimators=100; total time=   8.9s\n",
      "[CV] END catboost__depth=4, catboost__iterations=500, catboost__learning_rate=0.01, lgbm__learning_rate=0.01, lgbm__n_estimators=100, lgbm__num_leaves=31, xgboost__learning_rate=0.01, xgboost__max_depth=6, xgboost__n_estimators=500; total time=  11.3s\n",
      "[CV] END catboost__depth=4, catboost__iterations=500, catboost__learning_rate=0.01, lgbm__learning_rate=0.01, lgbm__n_estimators=100, lgbm__num_leaves=31, xgboost__learning_rate=0.01, xgboost__max_depth=6, xgboost__n_estimators=500; total time=  10.5s\n",
      "[CV] END catboost__depth=4, catboost__iterations=500, catboost__learning_rate=0.01, lgbm__learning_rate=0.01, lgbm__n_estimators=100, lgbm__num_leaves=31, xgboost__learning_rate=0.01, xgboost__max_depth=9, xgboost__n_estimators=100; total time=   9.2s\n",
      "[LightGBM] [Info] Number of positive: 4673, number of negative: 3455\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002673 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3570\n",
      "[LightGBM] [Info] Number of data points in the train set: 8128, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.574926 -> initscore=0.301979\n",
      "[LightGBM] [Info] Start training from score 0.301979\n",
      "[CV] END catboost__depth=4, catboost__iterations=500, catboost__learning_rate=0.01, lgbm__learning_rate=0.01, lgbm__n_estimators=100, lgbm__num_leaves=31, xgboost__learning_rate=0.01, xgboost__max_depth=9, xgboost__n_estimators=100; total time=   9.5s\n",
      "[LightGBM] [Info] Number of positive: 4673, number of negative: 3455\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000993 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3570\n",
      "[LightGBM] [Info] Number of data points in the train set: 8128, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.574926 -> initscore=0.301979\n",
      "[LightGBM] [Info] Start training from score 0.301979\n",
      "[CV] END catboost__depth=4, catboost__iterations=500, catboost__learning_rate=0.01, lgbm__learning_rate=0.01, lgbm__n_estimators=100, lgbm__num_leaves=31, xgboost__learning_rate=0.01, xgboost__max_depth=9, xgboost__n_estimators=100; total time=   8.7s\n",
      "[CV] END catboost__depth=4, catboost__iterations=500, catboost__learning_rate=0.01, lgbm__learning_rate=0.01, lgbm__n_estimators=100, lgbm__num_leaves=31, xgboost__learning_rate=0.01, xgboost__max_depth=6, xgboost__n_estimators=500; total time=  10.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/susan/BTP/.venv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [10:38:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/susan/BTP/.venv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [10:38:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/susan/BTP/.venv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [10:38:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/susan/BTP/.venv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [10:38:32] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/susan/BTP/.venv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [10:38:32] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/susan/BTP/.venv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [10:38:32] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4673, number of negative: 3455\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003175 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3570\n",
      "[LightGBM] [Info] Number of data points in the train set: 8128, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.574926 -> initscore=0.301979\n",
      "[LightGBM] [Info] Start training from score 0.301979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/susan/BTP/.venv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [10:38:33] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/susan/BTP/.venv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [10:38:33] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4672, number of negative: 3456\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011780 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3570\n",
      "[LightGBM] [Info] Number of data points in the train set: 8128, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.574803 -> initscore=0.301475\n",
      "[LightGBM] [Info] Start training from score 0.301475\n",
      "[LightGBM] [Info] Number of positive: 4673, number of negative: 3455\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001395 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3570\n",
      "[LightGBM] [Info] Number of data points in the train set: 8128, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.574926 -> initscore=0.301979\n",
      "[LightGBM] [Info] Start training from score 0.301979\n",
      "[CV] END catboost__depth=4, catboost__iterations=500, catboost__learning_rate=0.01, lgbm__learning_rate=0.01, lgbm__n_estimators=100, lgbm__num_leaves=31, xgboost__learning_rate=0.01, xgboost__max_depth=9, xgboost__n_estimators=100; total time=   9.0s\n",
      "[CV] END catboost__depth=4, catboost__iterations=500, catboost__learning_rate=0.01, lgbm__learning_rate=0.01, lgbm__n_estimators=100, lgbm__num_leaves=31, xgboost__learning_rate=0.1, xgboost__max_depth=3, xgboost__n_estimators=100; total time=   7.5s\n",
      "[CV] END catboost__depth=4, catboost__iterations=500, catboost__learning_rate=0.01, lgbm__learning_rate=0.01, lgbm__n_estimators=100, lgbm__num_leaves=31, xgboost__learning_rate=0.1, xgboost__max_depth=3, xgboost__n_estimators=100; total time=   7.6s\n",
      "[LightGBM] [Info] Number of positive: 4673, number of negative: 3455\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000912 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3570\n",
      "[LightGBM] [Info] Number of data points in the train set: 8128, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.574926 -> initscore=0.301979\n",
      "[LightGBM] [Info] Start training from score 0.301979\n",
      "[LightGBM] [Info] Number of positive: 4672, number of negative: 3456\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003164 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3570\n",
      "[LightGBM] [Info] Number of data points in the train set: 8128, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.574803 -> initscore=0.301475\n",
      "[LightGBM] [Info] Start training from score 0.301475\n",
      "[LightGBM] [Info] Number of positive: 4673, number of negative: 3455\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001988 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3570\n",
      "[LightGBM] [Info] Number of data points in the train set: 8128, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.574926 -> initscore=0.301979\n",
      "[LightGBM] [Info] Start training from score 0.301979\n",
      "[CV] END catboost__depth=4, catboost__iterations=500, catboost__learning_rate=0.01, lgbm__learning_rate=0.01, lgbm__n_estimators=100, lgbm__num_leaves=31, xgboost__learning_rate=0.01, xgboost__max_depth=9, xgboost__n_estimators=500; total time=  14.7s\n",
      "[CV] END catboost__depth=4, catboost__iterations=500, catboost__learning_rate=0.01, lgbm__learning_rate=0.01, lgbm__n_estimators=100, lgbm__num_leaves=31, xgboost__learning_rate=0.01, xgboost__max_depth=9, xgboost__n_estimators=500; total time=  15.2s\n",
      "[LightGBM] [Info] Number of positive: 4673, number of negative: 3455\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001311 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3570\n",
      "[LightGBM] [Info] Number of data points in the train set: 8128, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.574926 -> initscore=0.301979\n",
      "[LightGBM] [Info] Start training from score 0.301979\n",
      "[LightGBM] [Info] Number of positive: 4673, number of negative: 3455\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000978 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3570\n",
      "[LightGBM] [Info] Number of data points in the train set: 8128, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.574926 -> initscore=0.301979\n",
      "[LightGBM] [Info] Start training from score 0.301979\n",
      "[CV] END catboost__depth=4, catboost__iterations=500, catboost__learning_rate=0.01, lgbm__learning_rate=0.01, lgbm__n_estimators=100, lgbm__num_leaves=31, xgboost__learning_rate=0.01, xgboost__max_depth=9, xgboost__n_estimators=500; total time=  15.2s\n",
      "[CV] END catboost__depth=4, catboost__iterations=500, catboost__learning_rate=0.01, lgbm__learning_rate=0.01, lgbm__n_estimators=100, lgbm__num_leaves=31, xgboost__learning_rate=0.01, xgboost__max_depth=9, xgboost__n_estimators=500; total time=  15.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/susan/BTP/.venv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [10:38:42] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4673, number of negative: 3455\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001016 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3570\n",
      "[LightGBM] [Info] Number of data points in the train set: 8128, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.574926 -> initscore=0.301979\n",
      "[LightGBM] [Info] Start training from score 0.301979\n",
      "[CV] END catboost__depth=4, catboost__iterations=500, catboost__learning_rate=0.01, lgbm__learning_rate=0.01, lgbm__n_estimators=100, lgbm__num_leaves=31, xgboost__learning_rate=0.01, xgboost__max_depth=9, xgboost__n_estimators=500; total time=  16.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/susan/BTP/.venv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [10:38:43] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/susan/BTP/.venv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [10:38:43] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4673, number of negative: 3455\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001304 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3570\n",
      "[LightGBM] [Info] Number of data points in the train set: 8128, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.574926 -> initscore=0.301979\n",
      "[LightGBM] [Info] Start training from score 0.301979\n",
      "[LightGBM] [Info] Number of positive: 4673, number of negative: 3455\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002003 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3570\n",
      "[LightGBM] [Info] Number of data points in the train set: 8128, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.574926 -> initscore=0.301979\n",
      "[LightGBM] [Info] Start training from score 0.301979\n",
      "[CV] END catboost__depth=4, catboost__iterations=500, catboost__learning_rate=0.01, lgbm__learning_rate=0.01, lgbm__n_estimators=100, lgbm__num_leaves=31, xgboost__learning_rate=0.1, xgboost__max_depth=3, xgboost__n_estimators=100; total time=   9.0s\n",
      "[CV] END catboost__depth=4, catboost__iterations=500, catboost__learning_rate=0.01, lgbm__learning_rate=0.01, lgbm__n_estimators=100, lgbm__num_leaves=31, xgboost__learning_rate=0.1, xgboost__max_depth=3, xgboost__n_estimators=100; total time=   9.2s\n",
      "[CV] END catboost__depth=4, catboost__iterations=500, catboost__learning_rate=0.01, lgbm__learning_rate=0.01, lgbm__n_estimators=100, lgbm__num_leaves=31, xgboost__learning_rate=0.1, xgboost__max_depth=3, xgboost__n_estimators=100; total time=   9.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/susan/BTP/.venv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [10:38:47] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/susan/BTP/.venv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [10:38:47] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/susan/BTP/.venv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [10:38:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/susan/BTP/.venv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [10:38:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4672, number of negative: 3456\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000884 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3570\n",
      "[LightGBM] [Info] Number of data points in the train set: 8128, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.574803 -> initscore=0.301475\n",
      "[LightGBM] [Info] Start training from score 0.301475\n",
      "[LightGBM] [Info] Number of positive: 4673, number of negative: 3455\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000936 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3570\n",
      "[LightGBM] [Info] Number of data points in the train set: 8128, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.574926 -> initscore=0.301979\n",
      "[LightGBM] [Info] Start training from score 0.301979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/susan/BTP/.venv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [10:38:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4673, number of negative: 3455\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002351 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3570\n",
      "[LightGBM] [Info] Number of data points in the train set: 8128, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.574926 -> initscore=0.301979\n",
      "[LightGBM] [Info] Start training from score 0.301979\n",
      "[LightGBM] [Info] Number of positive: 4673, number of negative: 3455\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001442 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3570\n",
      "[LightGBM] [Info] Number of data points in the train set: 8128, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.574926 -> initscore=0.301979\n",
      "[LightGBM] [Info] Start training from score 0.301979\n",
      "[CV] END catboost__depth=4, catboost__iterations=500, catboost__learning_rate=0.01, lgbm__learning_rate=0.01, lgbm__n_estimators=100, lgbm__num_leaves=31, xgboost__learning_rate=0.1, xgboost__max_depth=3, xgboost__n_estimators=500; total time=   8.0s\n",
      "[CV] END catboost__depth=4, catboost__iterations=500, catboost__learning_rate=0.01, lgbm__learning_rate=0.01, lgbm__n_estimators=100, lgbm__num_leaves=31, xgboost__learning_rate=0.1, xgboost__max_depth=3, xgboost__n_estimators=500; total time=   8.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/susan/BTP/.venv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [10:38:49] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4673, number of negative: 3455\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003466 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3570\n",
      "[LightGBM] [Info] Number of data points in the train set: 8128, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.574926 -> initscore=0.301979\n",
      "[LightGBM] [Info] Start training from score 0.301979\n",
      "[CV] END catboost__depth=4, catboost__iterations=500, catboost__learning_rate=0.01, lgbm__learning_rate=0.01, lgbm__n_estimators=100, lgbm__num_leaves=31, xgboost__learning_rate=0.1, xgboost__max_depth=3, xgboost__n_estimators=500; total time=   7.8s\n",
      "[LightGBM] [Info] Number of positive: 4672, number of negative: 3456\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003282 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3570\n",
      "[LightGBM] [Info] Number of data points in the train set: 8128, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.574803 -> initscore=0.301475\n",
      "[LightGBM] [Info] Start training from score 0.301475\n",
      "[CV] END catboost__depth=4, catboost__iterations=500, catboost__learning_rate=0.01, lgbm__learning_rate=0.01, lgbm__n_estimators=100, lgbm__num_leaves=31, xgboost__learning_rate=0.1, xgboost__max_depth=3, xgboost__n_estimators=500; total time=   8.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/susan/BTP/.venv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [10:38:50] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END catboost__depth=4, catboost__iterations=500, catboost__learning_rate=0.01, lgbm__learning_rate=0.01, lgbm__n_estimators=100, lgbm__num_leaves=31, xgboost__learning_rate=0.1, xgboost__max_depth=3, xgboost__n_estimators=500; total time=   8.1s\n",
      "[LightGBM] [Info] Number of positive: 4673, number of negative: 3455\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001283 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3570\n",
      "[LightGBM] [Info] Number of data points in the train set: 8128, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.574926 -> initscore=0.301979\n",
      "[LightGBM] [Info] Start training from score 0.301979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/susan/BTP/.venv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [10:38:51] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END catboost__depth=4, catboost__iterations=500, catboost__learning_rate=0.01, lgbm__learning_rate=0.01, lgbm__n_estimators=100, lgbm__num_leaves=31, xgboost__learning_rate=0.1, xgboost__max_depth=6, xgboost__n_estimators=100; total time=   7.7s\n",
      "[LightGBM] [Info] Number of positive: 4673, number of negative: 3455\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000826 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3570\n",
      "[LightGBM] [Info] Number of data points in the train set: 8128, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.574926 -> initscore=0.301979\n",
      "[LightGBM] [Info] Start training from score 0.301979\n",
      "[CV] END catboost__depth=4, catboost__iterations=500, catboost__learning_rate=0.01, lgbm__learning_rate=0.01, lgbm__n_estimators=100, lgbm__num_leaves=31, xgboost__learning_rate=0.1, xgboost__max_depth=6, xgboost__n_estimators=100; total time=   7.7s\n",
      "[CV] END catboost__depth=4, catboost__iterations=500, catboost__learning_rate=0.01, lgbm__learning_rate=0.01, lgbm__n_estimators=100, lgbm__num_leaves=31, xgboost__learning_rate=0.1, xgboost__max_depth=6, xgboost__n_estimators=100; total time=   7.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/susan/BTP/.venv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [10:38:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/susan/BTP/.venv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [10:38:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/susan/BTP/.venv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [10:38:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/susan/BTP/.venv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [10:38:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4673, number of negative: 3455\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008103 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3570\n",
      "[LightGBM] [Info] Number of data points in the train set: 8128, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.574926 -> initscore=0.301979\n",
      "[LightGBM] [Info] Start training from score 0.301979\n",
      "[LightGBM] [Info] Number of positive: 4673, number of negative: 3455\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001874 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3570\n",
      "[LightGBM] [Info] Number of data points in the train set: 8128, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.574926 -> initscore=0.301979\n",
      "[LightGBM] [Info] Start training from score 0.301979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/susan/BTP/.venv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [10:38:56] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/susan/BTP/.venv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [10:38:57] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END catboost__depth=4, catboost__iterations=500, catboost__learning_rate=0.01, lgbm__learning_rate=0.01, lgbm__n_estimators=100, lgbm__num_leaves=31, xgboost__learning_rate=0.1, xgboost__max_depth=6, xgboost__n_estimators=100; total time=   7.6s\n",
      "[CV] END catboost__depth=4, catboost__iterations=500, catboost__learning_rate=0.01, lgbm__learning_rate=0.01, lgbm__n_estimators=100, lgbm__num_leaves=31, xgboost__learning_rate=0.1, xgboost__max_depth=6, xgboost__n_estimators=100; total time=   7.9s\n",
      "[LightGBM] [Info] Number of positive: 4673, number of negative: 3455\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000783 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3570\n",
      "[LightGBM] [Info] Number of data points in the train set: 8128, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.574926 -> initscore=0.301979\n",
      "[LightGBM] [Info] Start training from score 0.301979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/susan/BTP/.venv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [10:38:57] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/susan/BTP/.venv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [10:38:57] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4672, number of negative: 3456\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011960 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3570\n",
      "[LightGBM] [Info] Number of data points in the train set: 8128, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.574803 -> initscore=0.301475\n",
      "[LightGBM] [Info] Start training from score 0.301475\n",
      "[CV] END catboost__depth=4, catboost__iterations=500, catboost__learning_rate=0.01, lgbm__learning_rate=0.01, lgbm__n_estimators=100, lgbm__num_leaves=31, xgboost__learning_rate=0.1, xgboost__max_depth=6, xgboost__n_estimators=500; total time=   8.0s\n",
      "[LightGBM] [Info] Number of positive: 4672, number of negative: 3456\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015551 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3570\n",
      "[LightGBM] [Info] Number of data points in the train set: 8128, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.574803 -> initscore=0.301475\n",
      "[LightGBM] [Info] Start training from score 0.301475\n",
      "[LightGBM] [Info] Number of positive: 4673, number of negative: 3455\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001649 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3570\n",
      "[LightGBM] [Info] Number of data points in the train set: 8128, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.574926 -> initscore=0.301979\n",
      "[LightGBM] [Info] Start training from score 0.301979\n",
      "[CV] END catboost__depth=4, catboost__iterations=500, catboost__learning_rate=0.01, lgbm__learning_rate=0.01, lgbm__n_estimators=100, lgbm__num_leaves=31, xgboost__learning_rate=0.1, xgboost__max_depth=6, xgboost__n_estimators=500; total time=   8.9s\n",
      "[LightGBM] [Info] Number of positive: 4673, number of negative: 3455\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016828 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3570\n",
      "[LightGBM] [Info] Number of data points in the train set: 8128, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.574926 -> initscore=0.301979\n",
      "[LightGBM] [Info] Start training from score 0.301979\n",
      "[CV] END catboost__depth=4, catboost__iterations=500, catboost__learning_rate=0.01, lgbm__learning_rate=0.01, lgbm__n_estimators=100, lgbm__num_leaves=31, xgboost__learning_rate=0.1, xgboost__max_depth=9, xgboost__n_estimators=100; total time=   7.7s\n",
      "[LightGBM] [Info] Number of positive: 4673, number of negative: 3455\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000552 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3570\n",
      "[LightGBM] [Info] Number of data points in the train set: 8128, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.574926 -> initscore=0.301979\n",
      "[LightGBM] [Info] Start training from score 0.301979\n",
      "[CV] END catboost__depth=4, catboost__iterations=500, catboost__learning_rate=0.01, lgbm__learning_rate=0.01, lgbm__n_estimators=100, lgbm__num_leaves=31, xgboost__learning_rate=0.1, xgboost__max_depth=6, xgboost__n_estimators=500; total time=   9.4s\n",
      "[CV] END catboost__depth=4, catboost__iterations=500, catboost__learning_rate=0.01, lgbm__learning_rate=0.01, lgbm__n_estimators=100, lgbm__num_leaves=31, xgboost__learning_rate=0.1, xgboost__max_depth=6, xgboost__n_estimators=500; total time=   9.5s\n",
      "[CV] END catboost__depth=4, catboost__iterations=500, catboost__learning_rate=0.01, lgbm__learning_rate=0.01, lgbm__n_estimators=100, lgbm__num_leaves=31, xgboost__learning_rate=0.1, xgboost__max_depth=6, xgboost__n_estimators=500; total time=   9.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/susan/BTP/.venv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [10:39:03] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/susan/BTP/.venv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [10:39:03] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4673, number of negative: 3455\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002975 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3570\n",
      "[LightGBM] [Info] Number of data points in the train set: 8128, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.574926 -> initscore=0.301979\n",
      "[LightGBM] [Info] Start training from score 0.301979\n",
      "[LightGBM] [Info] Number of positive: 4673, number of negative: 3455\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001486 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3570\n",
      "[LightGBM] [Info] Number of data points in the train set: 8128, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.574926 -> initscore=0.301979\n",
      "[LightGBM] [Info] Start training from score 0.301979\n",
      "[CV] END catboost__depth=4, catboost__iterations=500, catboost__learning_rate=0.01, lgbm__learning_rate=0.01, lgbm__n_estimators=100, lgbm__num_leaves=31, xgboost__learning_rate=0.1, xgboost__max_depth=9, xgboost__n_estimators=100; total time=   8.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/susan/BTP/.venv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [10:39:05] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END catboost__depth=4, catboost__iterations=500, catboost__learning_rate=0.01, lgbm__learning_rate=0.01, lgbm__n_estimators=100, lgbm__num_leaves=31, xgboost__learning_rate=0.1, xgboost__max_depth=9, xgboost__n_estimators=100; total time=   8.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/susan/BTP/.venv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [10:39:06] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4673, number of negative: 3455\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001130 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3570\n",
      "[LightGBM] [Info] Number of data points in the train set: 8128, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.574926 -> initscore=0.301979\n",
      "[LightGBM] [Info] Start training from score 0.301979\n",
      "[LightGBM] [Info] Number of positive: 4673, number of negative: 3455\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001001 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3570\n",
      "[LightGBM] [Info] Number of data points in the train set: 8128, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.574926 -> initscore=0.301979\n",
      "[LightGBM] [Info] Start training from score 0.301979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/susan/BTP/.venv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [10:39:07] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/susan/BTP/.venv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [10:39:07] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/susan/BTP/.venv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [10:39:07] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END catboost__depth=4, catboost__iterations=500, catboost__learning_rate=0.01, lgbm__learning_rate=0.01, lgbm__n_estimators=100, lgbm__num_leaves=31, xgboost__learning_rate=0.1, xgboost__max_depth=9, xgboost__n_estimators=100; total time=   8.8s\n",
      "[CV] END catboost__depth=4, catboost__iterations=500, catboost__learning_rate=0.01, lgbm__learning_rate=0.01, lgbm__n_estimators=100, lgbm__num_leaves=31, xgboost__learning_rate=0.1, xgboost__max_depth=9, xgboost__n_estimators=100; total time=   8.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/susan/BTP/.venv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [10:39:08] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4673, number of negative: 3455\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001428 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3570\n",
      "[LightGBM] [Info] Number of data points in the train set: 8128, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.574926 -> initscore=0.301979\n",
      "[LightGBM] [Info] Start training from score 0.301979\n",
      "[LightGBM] [Info] Number of positive: 4672, number of negative: 3456\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002290 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3570\n",
      "[LightGBM] [Info] Number of data points in the train set: 8128, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.574803 -> initscore=0.301475\n",
      "[LightGBM] [Info] Start training from score 0.301475\n",
      "[LightGBM] [Info] Number of positive: 4673, number of negative: 3455\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001590 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3570\n",
      "[LightGBM] [Info] Number of data points in the train set: 8128, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.574926 -> initscore=0.301979\n",
      "[LightGBM] [Info] Start training from score 0.301979\n",
      "[LightGBM] [Info] Number of positive: 4673, number of negative: 3455\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002507 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3570\n",
      "[LightGBM] [Info] Number of data points in the train set: 8128, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.574926 -> initscore=0.301979\n",
      "[LightGBM] [Info] Start training from score 0.301979\n",
      "[CV] END catboost__depth=4, catboost__iterations=500, catboost__learning_rate=0.01, lgbm__learning_rate=0.01, lgbm__n_estimators=100, lgbm__num_leaves=31, xgboost__learning_rate=0.1, xgboost__max_depth=9, xgboost__n_estimators=500; total time=  10.3s\n",
      "[CV] END catboost__depth=4, catboost__iterations=500, catboost__learning_rate=0.01, lgbm__learning_rate=0.01, lgbm__n_estimators=100, lgbm__num_leaves=31, xgboost__learning_rate=0.1, xgboost__max_depth=9, xgboost__n_estimators=500; total time=  10.6s\n",
      "[CV] END catboost__depth=4, catboost__iterations=500, catboost__learning_rate=0.01, lgbm__learning_rate=0.01, lgbm__n_estimators=100, lgbm__num_leaves=31, xgboost__learning_rate=0.1, xgboost__max_depth=9, xgboost__n_estimators=500; total time=   9.8s\n",
      "[CV] END catboost__depth=4, catboost__iterations=500, catboost__learning_rate=0.01, lgbm__learning_rate=0.01, lgbm__n_estimators=100, lgbm__num_leaves=31, xgboost__learning_rate=0.1, xgboost__max_depth=9, xgboost__n_estimators=500; total time=   9.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/susan/BTP/.venv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [10:39:12] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/susan/BTP/.venv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [10:39:12] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4672, number of negative: 3456\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002638 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3570\n",
      "[LightGBM] [Info] Number of data points in the train set: 8128, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.574803 -> initscore=0.301475\n",
      "[LightGBM] [Info] Start training from score 0.301475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/susan/BTP/.venv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [10:39:13] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4673, number of negative: 3455\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001220 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3570\n",
      "[LightGBM] [Info] Number of data points in the train set: 8128, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.574926 -> initscore=0.301979\n",
      "[LightGBM] [Info] Start training from score 0.301979\n",
      "[LightGBM] [Info] Number of positive: 4673, number of negative: 3455\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001296 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3570\n",
      "[LightGBM] [Info] Number of data points in the train set: 8128, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.574926 -> initscore=0.301979\n",
      "[LightGBM] [Info] Start training from score 0.301979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/susan/BTP/.venv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [10:39:14] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4673, number of negative: 3455\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001430 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3570\n",
      "[LightGBM] [Info] Number of data points in the train set: 8128, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.574926 -> initscore=0.301979\n",
      "[LightGBM] [Info] Start training from score 0.301979\n",
      "[CV] END catboost__depth=4, catboost__iterations=500, catboost__learning_rate=0.01, lgbm__learning_rate=0.01, lgbm__n_estimators=100, lgbm__num_leaves=63, xgboost__learning_rate=0.01, xgboost__max_depth=3, xgboost__n_estimators=100; total time=   9.7s\n",
      "[CV] END catboost__depth=4, catboost__iterations=500, catboost__learning_rate=0.01, lgbm__learning_rate=0.01, lgbm__n_estimators=100, lgbm__num_leaves=31, xgboost__learning_rate=0.1, xgboost__max_depth=9, xgboost__n_estimators=500; total time=  10.5s\n",
      "[CV] END catboost__depth=4, catboost__iterations=500, catboost__learning_rate=0.01, lgbm__learning_rate=0.01, lgbm__n_estimators=100, lgbm__num_leaves=63, xgboost__learning_rate=0.01, xgboost__max_depth=3, xgboost__n_estimators=100; total time=   9.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/susan/BTP/.venv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [10:39:18] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END catboost__depth=4, catboost__iterations=500, catboost__learning_rate=0.01, lgbm__learning_rate=0.01, lgbm__n_estimators=100, lgbm__num_leaves=63, xgboost__learning_rate=0.01, xgboost__max_depth=3, xgboost__n_estimators=100; total time=  10.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/susan/BTP/.venv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [10:39:18] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/susan/BTP/.venv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [10:39:18] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4673, number of negative: 3455\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001319 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3570\n",
      "[LightGBM] [Info] Number of data points in the train set: 8128, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.574926 -> initscore=0.301979\n",
      "[LightGBM] [Info] Start training from score 0.301979\n",
      "[LightGBM] [Info] Number of positive: 4673, number of negative: 3455\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001100 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3570\n",
      "[LightGBM] [Info] Number of data points in the train set: 8128, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.574926 -> initscore=0.301979\n",
      "[LightGBM] [Info] Start training from score 0.301979\n",
      "[LightGBM] [Info] Number of positive: 4672, number of negative: 3456\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001432 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3570\n",
      "[LightGBM] [Info] Number of data points in the train set: 8128, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.574803 -> initscore=0.301475\n",
      "[LightGBM] [Info] Start training from score 0.301475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/susan/BTP/.venv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [10:39:20] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END catboost__depth=4, catboost__iterations=500, catboost__learning_rate=0.01, lgbm__learning_rate=0.01, lgbm__n_estimators=100, lgbm__num_leaves=63, xgboost__learning_rate=0.01, xgboost__max_depth=3, xgboost__n_estimators=100; total time=  11.5s\n",
      "[CV] END catboost__depth=4, catboost__iterations=500, catboost__learning_rate=0.01, lgbm__learning_rate=0.01, lgbm__n_estimators=100, lgbm__num_leaves=63, xgboost__learning_rate=0.01, xgboost__max_depth=3, xgboost__n_estimators=100; total time=  11.4s\n",
      "[LightGBM] [Info] Number of positive: 4673, number of negative: 3455\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001292 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3570\n",
      "[LightGBM] [Info] Number of data points in the train set: 8128, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.574926 -> initscore=0.301979\n",
      "[LightGBM] [Info] Start training from score 0.301979\n",
      "[CV] END catboost__depth=4, catboost__iterations=500, catboost__learning_rate=0.01, lgbm__learning_rate=0.01, lgbm__n_estimators=100, lgbm__num_leaves=63, xgboost__learning_rate=0.01, xgboost__max_depth=3, xgboost__n_estimators=500; total time=  12.3s\n",
      "[CV] END catboost__depth=4, catboost__iterations=500, catboost__learning_rate=0.01, lgbm__learning_rate=0.01, lgbm__n_estimators=100, lgbm__num_leaves=63, xgboost__learning_rate=0.01, xgboost__max_depth=3, xgboost__n_estimators=500; total time=  13.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/susan/BTP/.venv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [10:39:25] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/susan/BTP/.venv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [10:39:26] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/susan/BTP/.venv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [10:39:26] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4673, number of negative: 3455\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000566 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3570\n",
      "[LightGBM] [Info] Number of data points in the train set: 8128, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.574926 -> initscore=0.301979\n",
      "[LightGBM] [Info] Start training from score 0.301979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/susan/BTP/.venv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [10:39:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4673, number of negative: 3455\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005622 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3570\n",
      "[LightGBM] [Info] Number of data points in the train set: 8128, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.574926 -> initscore=0.301979\n",
      "[LightGBM] [Info] Start training from score 0.301979\n",
      "[LightGBM] [Info] Number of positive: 4673, number of negative: 3455\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001381 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3570\n",
      "[LightGBM] [Info] Number of data points in the train set: 8128, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.574926 -> initscore=0.301979\n",
      "[LightGBM] [Info] Start training from score 0.301979\n",
      "[LightGBM] [Info] Number of positive: 4672, number of negative: 3456\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001263 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3570\n",
      "[LightGBM] [Info] Number of data points in the train set: 8128, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.574803 -> initscore=0.301475\n",
      "[LightGBM] [Info] Start training from score 0.301475\n",
      "[CV] END catboost__depth=4, catboost__iterations=500, catboost__learning_rate=0.01, lgbm__learning_rate=0.01, lgbm__n_estimators=100, lgbm__num_leaves=63, xgboost__learning_rate=0.01, xgboost__max_depth=3, xgboost__n_estimators=500; total time=  13.5s\n",
      "[CV] END catboost__depth=4, catboost__iterations=500, catboost__learning_rate=0.01, lgbm__learning_rate=0.01, lgbm__n_estimators=100, lgbm__num_leaves=63, xgboost__learning_rate=0.01, xgboost__max_depth=3, xgboost__n_estimators=500; total time=  14.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/susan/BTP/.venv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [10:39:30] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END catboost__depth=4, catboost__iterations=500, catboost__learning_rate=0.01, lgbm__learning_rate=0.01, lgbm__n_estimators=100, lgbm__num_leaves=63, xgboost__learning_rate=0.01, xgboost__max_depth=3, xgboost__n_estimators=500; total time=  13.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/susan/BTP/.venv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [10:39:30] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4673, number of negative: 3455\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001082 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3570\n",
      "[LightGBM] [Info] Number of data points in the train set: 8128, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.574926 -> initscore=0.301979\n",
      "[LightGBM] [Info] Start training from score 0.301979\n",
      "[CV] END catboost__depth=4, catboost__iterations=500, catboost__learning_rate=0.01, lgbm__learning_rate=0.01, lgbm__n_estimators=100, lgbm__num_leaves=63, xgboost__learning_rate=0.01, xgboost__max_depth=6, xgboost__n_estimators=100; total time=  12.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/susan/BTP/.venv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [10:39:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4673, number of negative: 3455\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001656 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3570\n",
      "[LightGBM] [Info] Number of data points in the train set: 8128, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.574926 -> initscore=0.301979\n",
      "[LightGBM] [Info] Start training from score 0.301979\n",
      "[LightGBM] [Info] Number of positive: 4673, number of negative: 3455\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001362 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3570\n",
      "[LightGBM] [Info] Number of data points in the train set: 8128, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.574926 -> initscore=0.301979\n",
      "[LightGBM] [Info] Start training from score 0.301979\n",
      "[CV] END catboost__depth=4, catboost__iterations=500, catboost__learning_rate=0.01, lgbm__learning_rate=0.01, lgbm__n_estimators=100, lgbm__num_leaves=63, xgboost__learning_rate=0.01, xgboost__max_depth=6, xgboost__n_estimators=100; total time=  10.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/susan/BTP/.venv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [10:39:32] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END catboost__depth=4, catboost__iterations=500, catboost__learning_rate=0.01, lgbm__learning_rate=0.01, lgbm__n_estimators=100, lgbm__num_leaves=63, xgboost__learning_rate=0.01, xgboost__max_depth=6, xgboost__n_estimators=100; total time=  11.4s\n",
      "[LightGBM] [Info] Number of positive: 4673, number of negative: 3455\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001049 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3570\n",
      "[LightGBM] [Info] Number of data points in the train set: 8128, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.574926 -> initscore=0.301979\n",
      "[LightGBM] [Info] Start training from score 0.301979\n",
      "[CV] END catboost__depth=4, catboost__iterations=500, catboost__learning_rate=0.01, lgbm__learning_rate=0.01, lgbm__n_estimators=100, lgbm__num_leaves=63, xgboost__learning_rate=0.01, xgboost__max_depth=6, xgboost__n_estimators=100; total time=  11.0s\n",
      "[CV] END catboost__depth=4, catboost__iterations=500, catboost__learning_rate=0.01, lgbm__learning_rate=0.01, lgbm__n_estimators=100, lgbm__num_leaves=63, xgboost__learning_rate=0.01, xgboost__max_depth=6, xgboost__n_estimators=100; total time=  10.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/susan/BTP/.venv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [10:39:36] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/susan/BTP/.venv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [10:39:37] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/susan/BTP/.venv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [10:39:37] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/susan/BTP/.venv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [10:39:37] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/susan/BTP/.venv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [10:39:39] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4672, number of negative: 3456\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000987 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3570\n",
      "[LightGBM] [Info] Number of data points in the train set: 8128, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.574803 -> initscore=0.301475\n",
      "[LightGBM] [Info] Start training from score 0.301475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/susan/BTP/.venv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [10:39:40] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/susan/BTP/.venv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [10:39:41] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4673, number of negative: 3455\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001052 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3570\n",
      "[LightGBM] [Info] Number of data points in the train set: 8128, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.574926 -> initscore=0.301979\n",
      "[LightGBM] [Info] Start training from score 0.301979\n",
      "[LightGBM] [Info] Number of positive: 4673, number of negative: 3455\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001160 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3570\n",
      "[LightGBM] [Info] Number of data points in the train set: 8128, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.574926 -> initscore=0.301979\n",
      "[LightGBM] [Info] Start training from score 0.301979\n",
      "[CV] END catboost__depth=4, catboost__iterations=500, catboost__learning_rate=0.01, lgbm__learning_rate=0.01, lgbm__n_estimators=100, lgbm__num_leaves=63, xgboost__learning_rate=0.01, xgboost__max_depth=6, xgboost__n_estimators=500; total time=  13.0s\n",
      "[LightGBM] [Info] Number of positive: 4673, number of negative: 3455\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003551 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3570\n",
      "[LightGBM] [Info] Number of data points in the train set: 8128, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.574926 -> initscore=0.301979\n",
      "[LightGBM] [Info] Start training from score 0.301979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/susan/BTP/.venv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [10:39:43] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4672, number of negative: 3456\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001129 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3570\n",
      "[LightGBM] [Info] Number of data points in the train set: 8128, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.574803 -> initscore=0.301475\n",
      "[LightGBM] [Info] Start training from score 0.301475\n",
      "[CV] END catboost__depth=4, catboost__iterations=500, catboost__learning_rate=0.01, lgbm__learning_rate=0.01, lgbm__n_estimators=100, lgbm__num_leaves=63, xgboost__learning_rate=0.01, xgboost__max_depth=6, xgboost__n_estimators=500; total time=  13.7s\n",
      "[CV] END catboost__depth=4, catboost__iterations=500, catboost__learning_rate=0.01, lgbm__learning_rate=0.01, lgbm__n_estimators=100, lgbm__num_leaves=63, xgboost__learning_rate=0.01, xgboost__max_depth=6, xgboost__n_estimators=500; total time=  13.1s\n",
      "[LightGBM] [Info] Number of positive: 4673, number of negative: 3455\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001852 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3570\n",
      "[LightGBM] [Info] Number of data points in the train set: 8128, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.574926 -> initscore=0.301979\n",
      "[LightGBM] [Info] Start training from score 0.301979\n",
      "[CV] END catboost__depth=4, catboost__iterations=500, catboost__learning_rate=0.01, lgbm__learning_rate=0.01, lgbm__n_estimators=100, lgbm__num_leaves=63, xgboost__learning_rate=0.01, xgboost__max_depth=6, xgboost__n_estimators=500; total time=  14.4s\n",
      "[LightGBM] [Info] Number of positive: 4673, number of negative: 3455\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001900 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3570\n",
      "[LightGBM] [Info] Number of data points in the train set: 8128, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.574926 -> initscore=0.301979\n",
      "[LightGBM] [Info] Start training from score 0.301979\n",
      "[CV] END catboost__depth=4, catboost__iterations=500, catboost__learning_rate=0.01, lgbm__learning_rate=0.01, lgbm__n_estimators=100, lgbm__num_leaves=63, xgboost__learning_rate=0.01, xgboost__max_depth=9, xgboost__n_estimators=100; total time=  11.9s\n",
      "[LightGBM] [Info] Number of positive: 4673, number of negative: 3455\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005076 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3570\n",
      "[LightGBM] [Info] Number of data points in the train set: 8128, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.574926 -> initscore=0.301979\n",
      "[LightGBM] [Info] Start training from score 0.301979\n",
      "[CV] END catboost__depth=4, catboost__iterations=500, catboost__learning_rate=0.01, lgbm__learning_rate=0.01, lgbm__n_estimators=100, lgbm__num_leaves=63, xgboost__learning_rate=0.01, xgboost__max_depth=9, xgboost__n_estimators=100; total time=  12.7s\n",
      "[CV] END catboost__depth=4, catboost__iterations=500, catboost__learning_rate=0.01, lgbm__learning_rate=0.01, lgbm__n_estimators=100, lgbm__num_leaves=63, xgboost__learning_rate=0.01, xgboost__max_depth=6, xgboost__n_estimators=500; total time=  14.9s\n",
      "[CV] END catboost__depth=4, catboost__iterations=500, catboost__learning_rate=0.01, lgbm__learning_rate=0.01, lgbm__n_estimators=100, lgbm__num_leaves=63, xgboost__learning_rate=0.01, xgboost__max_depth=9, xgboost__n_estimators=100; total time=  12.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/susan/BTP/.venv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [10:39:49] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/susan/BTP/.venv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [10:39:51] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/susan/BTP/.venv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [10:39:51] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4673, number of negative: 3455\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.049153 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3570\n",
      "[LightGBM] [Info] Number of data points in the train set: 8128, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.574926 -> initscore=0.301979\n",
      "[LightGBM] [Info] Start training from score 0.301979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/susan/BTP/.venv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [10:39:52] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/susan/BTP/.venv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [10:39:52] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END catboost__depth=4, catboost__iterations=500, catboost__learning_rate=0.01, lgbm__learning_rate=0.01, lgbm__n_estimators=100, lgbm__num_leaves=63, xgboost__learning_rate=0.01, xgboost__max_depth=9, xgboost__n_estimators=100; total time=  11.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/susan/BTP/.venv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [10:39:53] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4673, number of negative: 3455\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000753 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3570\n",
      "[LightGBM] [Info] Number of data points in the train set: 8128, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.574926 -> initscore=0.301979\n",
      "[LightGBM] [Info] Start training from score 0.301979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/susan/BTP/.venv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [10:39:54] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/susan/BTP/.venv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [10:39:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4672, number of negative: 3456\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001491 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3570\n",
      "[LightGBM] [Info] Number of data points in the train set: 8128, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.574803 -> initscore=0.301475\n",
      "[LightGBM] [Info] Start training from score 0.301475\n",
      "[CV] END catboost__depth=4, catboost__iterations=500, catboost__learning_rate=0.01, lgbm__learning_rate=0.01, lgbm__n_estimators=100, lgbm__num_leaves=63, xgboost__learning_rate=0.01, xgboost__max_depth=9, xgboost__n_estimators=100; total time=  11.6s\n",
      "[CV] END catboost__depth=4, catboost__iterations=500, catboost__learning_rate=0.01, lgbm__learning_rate=0.01, lgbm__n_estimators=100, lgbm__num_leaves=63, xgboost__learning_rate=0.1, xgboost__max_depth=3, xgboost__n_estimators=100; total time=   9.4s\n",
      "[LightGBM] [Info] Number of positive: 4672, number of negative: 3456\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.032430 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3570\n",
      "[LightGBM] [Info] Number of data points in the train set: 8128, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.574803 -> initscore=0.301475\n",
      "[LightGBM] [Info] Start training from score 0.301475\n",
      "[LightGBM] [Info] Number of positive: 4673, number of negative: 3455\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001181 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3570\n",
      "[LightGBM] [Info] Number of data points in the train set: 8128, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.574926 -> initscore=0.301979\n",
      "[LightGBM] [Info] Start training from score 0.301979\n",
      "[LightGBM] [Info] Number of positive: 4673, number of negative: 3455\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000513 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3570\n",
      "[LightGBM] [Info] Number of data points in the train set: 8128, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.574926 -> initscore=0.301979\n",
      "[LightGBM] [Info] Start training from score 0.301979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/susan/BTP/.venv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [10:40:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4673, number of negative: 3455\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001796 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3570\n",
      "[LightGBM] [Info] Number of data points in the train set: 8128, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.574926 -> initscore=0.301979\n",
      "[LightGBM] [Info] Start training from score 0.301979\n",
      "[LightGBM] [Info] Number of positive: 4673, number of negative: 3455\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001619 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3570\n",
      "[LightGBM] [Info] Number of data points in the train set: 8128, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.574926 -> initscore=0.301979\n",
      "[LightGBM] [Info] Start training from score 0.301979\n",
      "[CV] END catboost__depth=4, catboost__iterations=500, catboost__learning_rate=0.01, lgbm__learning_rate=0.01, lgbm__n_estimators=100, lgbm__num_leaves=63, xgboost__learning_rate=0.01, xgboost__max_depth=9, xgboost__n_estimators=500; total time=  18.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/susan/BTP/.venv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [10:40:04] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4673, number of negative: 3455\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007359 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3570\n",
      "[LightGBM] [Info] Number of data points in the train set: 8128, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.574926 -> initscore=0.301979\n",
      "[LightGBM] [Info] Start training from score 0.301979\n",
      "[LightGBM] [Info] Number of positive: 4673, number of negative: 3455\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004398 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3570\n",
      "[LightGBM] [Info] Number of data points in the train set: 8128, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.574926 -> initscore=0.301979\n",
      "[LightGBM] [Info] Start training from score 0.301979\n",
      "[CV] END catboost__depth=4, catboost__iterations=500, catboost__learning_rate=0.01, lgbm__learning_rate=0.01, lgbm__n_estimators=100, lgbm__num_leaves=63, xgboost__learning_rate=0.01, xgboost__max_depth=9, xgboost__n_estimators=500; total time=  20.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/susan/BTP/.venv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [10:40:06] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4673, number of negative: 3455\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002283 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3570\n",
      "[LightGBM] [Info] Number of data points in the train set: 8128, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.574926 -> initscore=0.301979\n",
      "[LightGBM] [Info] Start training from score 0.301979\n",
      "[CV] END catboost__depth=4, catboost__iterations=500, catboost__learning_rate=0.01, lgbm__learning_rate=0.01, lgbm__n_estimators=100, lgbm__num_leaves=63, xgboost__learning_rate=0.01, xgboost__max_depth=9, xgboost__n_estimators=500; total time=  21.3s\n",
      "[CV] END catboost__depth=4, catboost__iterations=500, catboost__learning_rate=0.01, lgbm__learning_rate=0.01, lgbm__n_estimators=100, lgbm__num_leaves=63, xgboost__learning_rate=0.1, xgboost__max_depth=3, xgboost__n_estimators=100; total time=  14.2s\n",
      "[CV] END catboost__depth=4, catboost__iterations=500, catboost__learning_rate=0.01, lgbm__learning_rate=0.01, lgbm__n_estimators=100, lgbm__num_leaves=63, xgboost__learning_rate=0.01, xgboost__max_depth=9, xgboost__n_estimators=500; total time=  20.9s\n",
      "[CV] END catboost__depth=4, catboost__iterations=500, catboost__learning_rate=0.01, lgbm__learning_rate=0.01, lgbm__n_estimators=100, lgbm__num_leaves=63, xgboost__learning_rate=0.01, xgboost__max_depth=9, xgboost__n_estimators=500; total time=  21.0s\n",
      "[CV] END catboost__depth=4, catboost__iterations=500, catboost__learning_rate=0.01, lgbm__learning_rate=0.01, lgbm__n_estimators=100, lgbm__num_leaves=63, xgboost__learning_rate=0.1, xgboost__max_depth=3, xgboost__n_estimators=100; total time=  13.4s\n",
      "[CV] END catboost__depth=4, catboost__iterations=500, catboost__learning_rate=0.01, lgbm__learning_rate=0.01, lgbm__n_estimators=100, lgbm__num_leaves=63, xgboost__learning_rate=0.1, xgboost__max_depth=3, xgboost__n_estimators=100; total time=  11.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/susan/BTP/.venv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [10:40:10] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4673, number of negative: 3455\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001094 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3570\n",
      "[LightGBM] [Info] Number of data points in the train set: 8128, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.574926 -> initscore=0.301979\n",
      "[LightGBM] [Info] Start training from score 0.301979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/susan/BTP/.venv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [10:40:12] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END catboost__depth=4, catboost__iterations=500, catboost__learning_rate=0.01, lgbm__learning_rate=0.01, lgbm__n_estimators=100, lgbm__num_leaves=63, xgboost__learning_rate=0.1, xgboost__max_depth=3, xgboost__n_estimators=100; total time=   9.7s\n",
      "[LightGBM] [Info] Number of positive: 4672, number of negative: 3456\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007567 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3570\n",
      "[LightGBM] [Info] Number of data points in the train set: 8128, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.574803 -> initscore=0.301475\n",
      "[LightGBM] [Info] Start training from score 0.301475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/susan/BTP/.venv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [10:40:13] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/susan/BTP/.venv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [10:40:13] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/susan/BTP/.venv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [10:40:14] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4673, number of negative: 3455\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001012 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3570\n",
      "[LightGBM] [Info] Number of data points in the train set: 8128, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.574926 -> initscore=0.301979\n",
      "[LightGBM] [Info] Start training from score 0.301979\n",
      "[CV] END catboost__depth=4, catboost__iterations=500, catboost__learning_rate=0.01, lgbm__learning_rate=0.01, lgbm__n_estimators=100, lgbm__num_leaves=63, xgboost__learning_rate=0.1, xgboost__max_depth=3, xgboost__n_estimators=500; total time=   9.6s\n",
      "[LightGBM] [Info] Number of positive: 4673, number of negative: 3455\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002065 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3570\n",
      "[LightGBM] [Info] Number of data points in the train set: 8128, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.574926 -> initscore=0.301979\n",
      "[LightGBM] [Info] Start training from score 0.301979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/susan/BTP/.venv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [10:40:15] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/susan/BTP/.venv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [10:40:16] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/susan/BTP/.venv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [10:40:16] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4673, number of negative: 3455\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000799 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3570\n",
      "[LightGBM] [Info] Number of data points in the train set: 8128, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.574926 -> initscore=0.301979\n",
      "[LightGBM] [Info] Start training from score 0.301979\n",
      "[LightGBM] [Info] Number of positive: 4672, number of negative: 3456\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001184 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3570\n",
      "[LightGBM] [Info] Number of data points in the train set: 8128, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.574803 -> initscore=0.301475\n",
      "[LightGBM] [Info] Start training from score 0.301475\n",
      "[LightGBM] [Info] Number of positive: 4673, number of negative: 3455\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001133 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3570\n",
      "[LightGBM] [Info] Number of data points in the train set: 8128, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.574926 -> initscore=0.301979\n",
      "[LightGBM] [Info] Start training from score 0.301979\n",
      "[CV] END catboost__depth=4, catboost__iterations=500, catboost__learning_rate=0.01, lgbm__learning_rate=0.01, lgbm__n_estimators=100, lgbm__num_leaves=63, xgboost__learning_rate=0.1, xgboost__max_depth=3, xgboost__n_estimators=500; total time=  10.6s\n",
      "[CV] END catboost__depth=4, catboost__iterations=500, catboost__learning_rate=0.01, lgbm__learning_rate=0.01, lgbm__n_estimators=100, lgbm__num_leaves=63, xgboost__learning_rate=0.1, xgboost__max_depth=3, xgboost__n_estimators=500; total time=  10.1s\n",
      "[LightGBM] [Info] Number of positive: 4673, number of negative: 3455\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001611 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3570\n",
      "[LightGBM] [Info] Number of data points in the train set: 8128, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.574926 -> initscore=0.301979\n",
      "[LightGBM] [Info] Start training from score 0.301979\n",
      "[CV] END catboost__depth=4, catboost__iterations=500, catboost__learning_rate=0.01, lgbm__learning_rate=0.01, lgbm__n_estimators=100, lgbm__num_leaves=63, xgboost__learning_rate=0.1, xgboost__max_depth=3, xgboost__n_estimators=500; total time=  12.9s\n",
      "[CV] END catboost__depth=4, catboost__iterations=500, catboost__learning_rate=0.01, lgbm__learning_rate=0.01, lgbm__n_estimators=100, lgbm__num_leaves=63, xgboost__learning_rate=0.1, xgboost__max_depth=6, xgboost__n_estimators=100; total time=  12.4s\n",
      "[CV] END catboost__depth=4, catboost__iterations=500, catboost__learning_rate=0.01, lgbm__learning_rate=0.01, lgbm__n_estimators=100, lgbm__num_leaves=63, xgboost__learning_rate=0.1, xgboost__max_depth=6, xgboost__n_estimators=100; total time=  11.9s\n",
      "[CV] END catboost__depth=4, catboost__iterations=500, catboost__learning_rate=0.01, lgbm__learning_rate=0.01, lgbm__n_estimators=100, lgbm__num_leaves=63, xgboost__learning_rate=0.1, xgboost__max_depth=3, xgboost__n_estimators=500; total time=  12.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/susan/BTP/.venv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [10:40:21] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4673, number of negative: 3455\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000619 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3570\n",
      "[LightGBM] [Info] Number of data points in the train set: 8128, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.574926 -> initscore=0.301979\n",
      "[LightGBM] [Info] Start training from score 0.301979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/susan/BTP/.venv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [10:40:23] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END catboost__depth=4, catboost__iterations=500, catboost__learning_rate=0.01, lgbm__learning_rate=0.01, lgbm__n_estimators=100, lgbm__num_leaves=63, xgboost__learning_rate=0.1, xgboost__max_depth=6, xgboost__n_estimators=100; total time=  11.3s\n",
      "[LightGBM] [Info] Number of positive: 4673, number of negative: 3455\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001407 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3570\n",
      "[LightGBM] [Info] Number of data points in the train set: 8128, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.574926 -> initscore=0.301979\n",
      "[LightGBM] [Info] Start training from score 0.301979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/susan/BTP/.venv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [10:40:25] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/susan/BTP/.venv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [10:40:25] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4673, number of negative: 3455\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001182 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3570\n",
      "[LightGBM] [Info] Number of data points in the train set: 8128, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.574926 -> initscore=0.301979\n",
      "[LightGBM] [Info] Start training from score 0.301979\n",
      "[CV] END catboost__depth=4, catboost__iterations=500, catboost__learning_rate=0.01, lgbm__learning_rate=0.01, lgbm__n_estimators=100, lgbm__num_leaves=63, xgboost__learning_rate=0.1, xgboost__max_depth=6, xgboost__n_estimators=100; total time=  11.1s\n",
      "[LightGBM] [Info] Number of positive: 4672, number of negative: 3456\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001358 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3570\n",
      "[LightGBM] [Info] Number of data points in the train set: 8128, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.574803 -> initscore=0.301475\n",
      "[LightGBM] [Info] Start training from score 0.301475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/susan/BTP/.venv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [10:40:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END catboost__depth=4, catboost__iterations=500, catboost__learning_rate=0.01, lgbm__learning_rate=0.01, lgbm__n_estimators=100, lgbm__num_leaves=63, xgboost__learning_rate=0.1, xgboost__max_depth=6, xgboost__n_estimators=100; total time=  10.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/susan/BTP/.venv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [10:40:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/susan/BTP/.venv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [10:40:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/susan/BTP/.venv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [10:40:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END catboost__depth=4, catboost__iterations=500, catboost__learning_rate=0.01, lgbm__learning_rate=0.01, lgbm__n_estimators=100, lgbm__num_leaves=63, xgboost__learning_rate=0.1, xgboost__max_depth=6, xgboost__n_estimators=500; total time=  11.5s\n",
      "[LightGBM] [Info] Number of positive: 4673, number of negative: 3455\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001147 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3570\n",
      "[LightGBM] [Info] Number of data points in the train set: 8128, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.574926 -> initscore=0.301979\n",
      "[LightGBM] [Info] Start training from score 0.301979\n",
      "[LightGBM] [Info] Number of positive: 4673, number of negative: 3455\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001602 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3570\n",
      "[LightGBM] [Info] Number of data points in the train set: 8128, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.574926 -> initscore=0.301979\n",
      "[LightGBM] [Info] Start training from score 0.301979\n",
      "[LightGBM] [Info] Number of positive: 4673, number of negative: 3455\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001172 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3570\n",
      "[LightGBM] [Info] Number of data points in the train set: 8128, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.574926 -> initscore=0.301979\n",
      "[LightGBM] [Info] Start training from score 0.301979\n",
      "[LightGBM] [Info] Number of positive: 4673, number of negative: 3455\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005800 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3570\n",
      "[LightGBM] [Info] Number of data points in the train set: 8128, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.574926 -> initscore=0.301979\n",
      "[LightGBM] [Info] Start training from score 0.301979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/susan/BTP/.venv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [10:40:30] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END catboost__depth=4, catboost__iterations=500, catboost__learning_rate=0.01, lgbm__learning_rate=0.01, lgbm__n_estimators=100, lgbm__num_leaves=63, xgboost__learning_rate=0.1, xgboost__max_depth=6, xgboost__n_estimators=500; total time=  11.6s\n",
      "[LightGBM] [Info] Number of positive: 4672, number of negative: 3456\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002565 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3570\n",
      "[LightGBM] [Info] Number of data points in the train set: 8128, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.574803 -> initscore=0.301475\n",
      "[LightGBM] [Info] Start training from score 0.301475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/susan/BTP/.venv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [10:40:33] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END catboost__depth=4, catboost__iterations=500, catboost__learning_rate=0.01, lgbm__learning_rate=0.01, lgbm__n_estimators=100, lgbm__num_leaves=63, xgboost__learning_rate=0.1, xgboost__max_depth=6, xgboost__n_estimators=500; total time=  12.7s\n",
      "[CV] END catboost__depth=4, catboost__iterations=500, catboost__learning_rate=0.01, lgbm__learning_rate=0.01, lgbm__n_estimators=100, lgbm__num_leaves=63, xgboost__learning_rate=0.1, xgboost__max_depth=6, xgboost__n_estimators=500; total time=  12.8s\n",
      "[CV] END catboost__depth=4, catboost__iterations=500, catboost__learning_rate=0.01, lgbm__learning_rate=0.01, lgbm__n_estimators=100, lgbm__num_leaves=63, xgboost__learning_rate=0.1, xgboost__max_depth=6, xgboost__n_estimators=500; total time=  12.7s\n",
      "[LightGBM] [Info] Number of positive: 4673, number of negative: 3455\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001149 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3570\n",
      "[LightGBM] [Info] Number of data points in the train set: 8128, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.574926 -> initscore=0.301979\n",
      "[LightGBM] [Info] Start training from score 0.301979\n",
      "[CV] END catboost__depth=4, catboost__iterations=500, catboost__learning_rate=0.01, lgbm__learning_rate=0.01, lgbm__n_estimators=100, lgbm__num_leaves=63, xgboost__learning_rate=0.1, xgboost__max_depth=9, xgboost__n_estimators=100; total time=  11.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/susan/BTP/.venv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [10:40:35] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4673, number of negative: 3455\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000853 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3570\n",
      "[LightGBM] [Info] Number of data points in the train set: 8128, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.574926 -> initscore=0.301979\n",
      "[LightGBM] [Info] Start training from score 0.301979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/susan/BTP/.venv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [10:40:36] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END catboost__depth=4, catboost__iterations=500, catboost__learning_rate=0.01, lgbm__learning_rate=0.01, lgbm__n_estimators=100, lgbm__num_leaves=63, xgboost__learning_rate=0.1, xgboost__max_depth=9, xgboost__n_estimators=100; total time=  10.6s\n",
      "[LightGBM] [Info] Number of positive: 4673, number of negative: 3455\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001090 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3570\n",
      "[LightGBM] [Info] Number of data points in the train set: 8128, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.574926 -> initscore=0.301979\n",
      "[LightGBM] [Info] Start training from score 0.301979\n",
      "[CV] END catboost__depth=4, catboost__iterations=500, catboost__learning_rate=0.01, lgbm__learning_rate=0.01, lgbm__n_estimators=100, lgbm__num_leaves=63, xgboost__learning_rate=0.1, xgboost__max_depth=9, xgboost__n_estimators=100; total time=  10.2s\n",
      "[CV] END catboost__depth=4, catboost__iterations=500, catboost__learning_rate=0.01, lgbm__learning_rate=0.01, lgbm__n_estimators=100, lgbm__num_leaves=63, xgboost__learning_rate=0.1, xgboost__max_depth=9, xgboost__n_estimators=100; total time=  10.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/susan/BTP/.venv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [10:40:40] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/susan/BTP/.venv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [10:40:40] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/susan/BTP/.venv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [10:40:40] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4673, number of negative: 3455\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000945 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3570\n",
      "[LightGBM] [Info] Number of data points in the train set: 8128, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.574926 -> initscore=0.301979\n",
      "[LightGBM] [Info] Start training from score 0.301979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/susan/BTP/.venv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [10:40:41] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/susan/BTP/.venv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [10:40:42] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END catboost__depth=4, catboost__iterations=500, catboost__learning_rate=0.01, lgbm__learning_rate=0.01, lgbm__n_estimators=100, lgbm__num_leaves=63, xgboost__learning_rate=0.1, xgboost__max_depth=9, xgboost__n_estimators=100; total time=  10.1s\n",
      "[LightGBM] [Info] Number of positive: 4672, number of negative: 3456\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004925 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3570\n",
      "[LightGBM] [Info] Number of data points in the train set: 8128, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.574803 -> initscore=0.301475\n",
      "[LightGBM] [Info] Start training from score 0.301475\n",
      "[LightGBM] [Info] Number of positive: 4673, number of negative: 3455\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001093 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3570\n",
      "[LightGBM] [Info] Number of data points in the train set: 8128, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.574926 -> initscore=0.301979\n",
      "[LightGBM] [Info] Start training from score 0.301979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/susan/BTP/.venv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [10:40:43] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4673, number of negative: 3455\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001233 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3570\n",
      "[LightGBM] [Info] Number of data points in the train set: 8128, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.574926 -> initscore=0.301979\n",
      "[LightGBM] [Info] Start training from score 0.301979\n",
      "[LightGBM] [Info] Number of positive: 4673, number of negative: 3455\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001659 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3570\n",
      "[LightGBM] [Info] Number of data points in the train set: 8128, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.574926 -> initscore=0.301979\n",
      "[LightGBM] [Info] Start training from score 0.301979\n",
      "[CV] END catboost__depth=4, catboost__iterations=500, catboost__learning_rate=0.01, lgbm__learning_rate=0.01, lgbm__n_estimators=100, lgbm__num_leaves=63, xgboost__learning_rate=0.1, xgboost__max_depth=9, xgboost__n_estimators=500; total time=  11.0s\n",
      "[CV] END catboost__depth=4, catboost__iterations=500, catboost__learning_rate=0.01, lgbm__learning_rate=0.01, lgbm__n_estimators=100, lgbm__num_leaves=63, xgboost__learning_rate=0.1, xgboost__max_depth=9, xgboost__n_estimators=500; total time=  11.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/susan/BTP/.venv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [10:40:45] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END catboost__depth=4, catboost__iterations=500, catboost__learning_rate=0.01, lgbm__learning_rate=0.01, lgbm__n_estimators=100, lgbm__num_leaves=63, xgboost__learning_rate=0.1, xgboost__max_depth=9, xgboost__n_estimators=500; total time=  12.2s\n",
      "[LightGBM] [Info] Number of positive: 4672, number of negative: 3456\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001421 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3570\n",
      "[LightGBM] [Info] Number of data points in the train set: 8128, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.574803 -> initscore=0.301475\n",
      "[LightGBM] [Info] Start training from score 0.301475\n",
      "[LightGBM] [Info] Number of positive: 4673, number of negative: 3455\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001142 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3570\n",
      "[LightGBM] [Info] Number of data points in the train set: 8128, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.574926 -> initscore=0.301979\n",
      "[LightGBM] [Info] Start training from score 0.301979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/susan/BTP/.venv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [10:40:46] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4673, number of negative: 3455\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006153 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3570\n",
      "[LightGBM] [Info] Number of data points in the train set: 8128, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.574926 -> initscore=0.301979\n",
      "[LightGBM] [Info] Start training from score 0.301979\n",
      "[CV] END catboost__depth=4, catboost__iterations=500, catboost__learning_rate=0.01, lgbm__learning_rate=0.01, lgbm__n_estimators=100, lgbm__num_leaves=63, xgboost__learning_rate=0.1, xgboost__max_depth=9, xgboost__n_estimators=500; total time=  12.6s\n",
      "[CV] END catboost__depth=4, catboost__iterations=500, catboost__learning_rate=0.01, lgbm__learning_rate=0.01, lgbm__n_estimators=100, lgbm__num_leaves=63, xgboost__learning_rate=0.1, xgboost__max_depth=9, xgboost__n_estimators=500; total time=  12.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/susan/BTP/.venv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [10:40:51] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4673, number of negative: 3455\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001092 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3570\n",
      "[LightGBM] [Info] Number of data points in the train set: 8128, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.574926 -> initscore=0.301979\n",
      "[LightGBM] [Info] Start training from score 0.301979\n",
      "[CV] END catboost__depth=4, catboost__iterations=500, catboost__learning_rate=0.01, lgbm__learning_rate=0.01, lgbm__n_estimators=500, lgbm__num_leaves=31, xgboost__learning_rate=0.01, xgboost__max_depth=3, xgboost__n_estimators=100; total time=  15.4s\n",
      "[LightGBM] [Info] Number of positive: 4673, number of negative: 3455\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001275 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3570\n",
      "[LightGBM] [Info] Number of data points in the train set: 8128, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.574926 -> initscore=0.301979\n",
      "[LightGBM] [Info] Start training from score 0.301979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/susan/BTP/.venv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [10:40:53] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/susan/BTP/.venv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [10:40:53] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4673, number of negative: 3455\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020828 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3570\n",
      "[LightGBM] [Info] Number of data points in the train set: 8128, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.574926 -> initscore=0.301979\n",
      "[LightGBM] [Info] Start training from score 0.301979\n",
      "[CV] END catboost__depth=4, catboost__iterations=500, catboost__learning_rate=0.01, lgbm__learning_rate=0.01, lgbm__n_estimators=500, lgbm__num_leaves=31, xgboost__learning_rate=0.01, xgboost__max_depth=3, xgboost__n_estimators=100; total time=  15.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/susan/BTP/.venv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [10:40:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/susan/BTP/.venv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [10:40:56] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4672, number of negative: 3456\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002875 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3570\n",
      "[LightGBM] [Info] Number of data points in the train set: 8128, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.574803 -> initscore=0.301475\n",
      "[LightGBM] [Info] Start training from score 0.301475\n",
      "[CV] END catboost__depth=4, catboost__iterations=500, catboost__learning_rate=0.01, lgbm__learning_rate=0.01, lgbm__n_estimators=500, lgbm__num_leaves=31, xgboost__learning_rate=0.01, xgboost__max_depth=3, xgboost__n_estimators=100; total time=  15.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/susan/BTP/.venv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [10:40:58] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4673, number of negative: 3455\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001781 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3570\n",
      "[LightGBM] [Info] Number of data points in the train set: 8128, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.574926 -> initscore=0.301979\n",
      "[LightGBM] [Info] Start training from score 0.301979\n",
      "[LightGBM] [Info] Number of positive: 4673, number of negative: 3455\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015027 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3570\n",
      "[LightGBM] [Info] Number of data points in the train set: 8128, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.574926 -> initscore=0.301979\n",
      "[LightGBM] [Info] Start training from score 0.301979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/susan/BTP/.venv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [10:41:03] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/susan/BTP/.venv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [10:41:03] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END catboost__depth=4, catboost__iterations=500, catboost__learning_rate=0.01, lgbm__learning_rate=0.01, lgbm__n_estimators=500, lgbm__num_leaves=31, xgboost__learning_rate=0.01, xgboost__max_depth=3, xgboost__n_estimators=100; total time=  19.3s\n",
      "[CV] END catboost__depth=4, catboost__iterations=500, catboost__learning_rate=0.01, lgbm__learning_rate=0.01, lgbm__n_estimators=500, lgbm__num_leaves=31, xgboost__learning_rate=0.01, xgboost__max_depth=3, xgboost__n_estimators=100; total time=  20.4s\n",
      "[LightGBM] [Info] Number of positive: 4673, number of negative: 3455\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001750 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3570\n",
      "[LightGBM] [Info] Number of data points in the train set: 8128, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.574926 -> initscore=0.301979\n",
      "[LightGBM] [Info] Start training from score 0.301979\n",
      "[LightGBM] [Info] Number of positive: 4673, number of negative: 3455\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001260 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3570\n",
      "[LightGBM] [Info] Number of data points in the train set: 8128, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.574926 -> initscore=0.301979\n",
      "[LightGBM] [Info] Start training from score 0.301979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/susan/BTP/.venv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [10:41:07] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4672, number of negative: 3456\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013076 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3570\n",
      "[LightGBM] [Info] Number of data points in the train set: 8128, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.574803 -> initscore=0.301475\n",
      "[LightGBM] [Info] Start training from score 0.301475\n",
      "[CV] END catboost__depth=4, catboost__iterations=500, catboost__learning_rate=0.01, lgbm__learning_rate=0.01, lgbm__n_estimators=500, lgbm__num_leaves=31, xgboost__learning_rate=0.01, xgboost__max_depth=3, xgboost__n_estimators=500; total time=  23.7s\n",
      "[CV] END catboost__depth=4, catboost__iterations=500, catboost__learning_rate=0.01, lgbm__learning_rate=0.01, lgbm__n_estimators=500, lgbm__num_leaves=31, xgboost__learning_rate=0.01, xgboost__max_depth=3, xgboost__n_estimators=500; total time=  24.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/susan/BTP/.venv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [10:41:13] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/susan/BTP/.venv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [10:41:14] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4673, number of negative: 3455\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001147 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3570\n",
      "[LightGBM] [Info] Number of data points in the train set: 8128, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.574926 -> initscore=0.301979\n",
      "[LightGBM] [Info] Start training from score 0.301979\n",
      "[CV] END catboost__depth=4, catboost__iterations=500, catboost__learning_rate=0.01, lgbm__learning_rate=0.01, lgbm__n_estimators=500, lgbm__num_leaves=31, xgboost__learning_rate=0.01, xgboost__max_depth=3, xgboost__n_estimators=500; total time=  25.7s\n",
      "[LightGBM] [Info] Number of positive: 4673, number of negative: 3455\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003341 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3570\n",
      "[LightGBM] [Info] Number of data points in the train set: 8128, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.574926 -> initscore=0.301979\n",
      "[LightGBM] [Info] Start training from score 0.301979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/susan/BTP/.venv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [10:41:19] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END catboost__depth=4, catboost__iterations=500, catboost__learning_rate=0.01, lgbm__learning_rate=0.01, lgbm__n_estimators=500, lgbm__num_leaves=31, xgboost__learning_rate=0.01, xgboost__max_depth=3, xgboost__n_estimators=500; total time=  25.8s\n",
      "[CV] END catboost__depth=4, catboost__iterations=500, catboost__learning_rate=0.01, lgbm__learning_rate=0.01, lgbm__n_estimators=500, lgbm__num_leaves=31, xgboost__learning_rate=0.01, xgboost__max_depth=3, xgboost__n_estimators=500; total time=  25.9s\n",
      "[LightGBM] [Info] Number of positive: 4673, number of negative: 3455\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001465 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3570\n",
      "[LightGBM] [Info] Number of data points in the train set: 8128, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.574926 -> initscore=0.301979\n",
      "[LightGBM] [Info] Start training from score 0.301979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/susan/BTP/.venv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [10:41:21] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END catboost__depth=4, catboost__iterations=500, catboost__learning_rate=0.01, lgbm__learning_rate=0.01, lgbm__n_estimators=500, lgbm__num_leaves=31, xgboost__learning_rate=0.01, xgboost__max_depth=6, xgboost__n_estimators=100; total time=  24.7s\n",
      "[LightGBM] [Info] Number of positive: 4673, number of negative: 3455\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001420 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3570\n",
      "[LightGBM] [Info] Number of data points in the train set: 8128, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.574926 -> initscore=0.301979\n",
      "[LightGBM] [Info] Start training from score 0.301979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/susan/BTP/.venv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [10:41:24] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END catboost__depth=4, catboost__iterations=500, catboost__learning_rate=0.01, lgbm__learning_rate=0.01, lgbm__n_estimators=500, lgbm__num_leaves=31, xgboost__learning_rate=0.01, xgboost__max_depth=6, xgboost__n_estimators=100; total time=  22.6s\n",
      "[CV] END catboost__depth=4, catboost__iterations=500, catboost__learning_rate=0.01, lgbm__learning_rate=0.01, lgbm__n_estimators=500, lgbm__num_leaves=31, xgboost__learning_rate=0.01, xgboost__max_depth=6, xgboost__n_estimators=100; total time=  21.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/susan/BTP/.venv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [10:41:29] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/susan/BTP/.venv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [10:41:29] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END catboost__depth=4, catboost__iterations=500, catboost__learning_rate=0.01, lgbm__learning_rate=0.01, lgbm__n_estimators=500, lgbm__num_leaves=31, xgboost__learning_rate=0.01, xgboost__max_depth=6, xgboost__n_estimators=100; total time=  20.1s\n",
      "[LightGBM] [Info] Number of positive: 4672, number of negative: 3456\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001028 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3570\n",
      "[LightGBM] [Info] Number of data points in the train set: 8128, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.574803 -> initscore=0.301475\n",
      "[LightGBM] [Info] Start training from score 0.301475\n",
      "[CV] END catboost__depth=4, catboost__iterations=500, catboost__learning_rate=0.01, lgbm__learning_rate=0.01, lgbm__n_estimators=500, lgbm__num_leaves=31, xgboost__learning_rate=0.01, xgboost__max_depth=6, xgboost__n_estimators=100; total time=  19.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/susan/BTP/.venv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [10:41:32] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4673, number of negative: 3455\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001167 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3570\n",
      "[LightGBM] [Info] Number of data points in the train set: 8128, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.574926 -> initscore=0.301979\n",
      "[LightGBM] [Info] Start training from score 0.301979\n",
      "[LightGBM] [Info] Number of positive: 4673, number of negative: 3455\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001828 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3570\n",
      "[LightGBM] [Info] Number of data points in the train set: 8128, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.574926 -> initscore=0.301979\n",
      "[LightGBM] [Info] Start training from score 0.301979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/susan/BTP/.venv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [10:41:35] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/susan/BTP/.venv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [10:41:36] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4673, number of negative: 3455\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001150 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3570\n",
      "[LightGBM] [Info] Number of data points in the train set: 8128, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.574926 -> initscore=0.301979\n",
      "[LightGBM] [Info] Start training from score 0.301979\n",
      "[CV] END catboost__depth=4, catboost__iterations=500, catboost__learning_rate=0.01, lgbm__learning_rate=0.01, lgbm__n_estimators=500, lgbm__num_leaves=31, xgboost__learning_rate=0.01, xgboost__max_depth=6, xgboost__n_estimators=500; total time=  23.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/susan/BTP/.venv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [10:41:39] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4672, number of negative: 3456\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012600 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3570\n",
      "[LightGBM] [Info] Number of data points in the train set: 8128, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.574803 -> initscore=0.301475\n",
      "[LightGBM] [Info] Start training from score 0.301475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/susan/BTP/.venv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [10:41:40] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4673, number of negative: 3455\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001981 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3570\n",
      "[LightGBM] [Info] Number of data points in the train set: 8128, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.574926 -> initscore=0.301979\n",
      "[LightGBM] [Info] Start training from score 0.301979\n",
      "[LightGBM] [Info] Number of positive: 4673, number of negative: 3455\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.047815 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3570\n",
      "[LightGBM] [Info] Number of data points in the train set: 8128, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.574926 -> initscore=0.301979\n",
      "[LightGBM] [Info] Start training from score 0.301979\n",
      "[LightGBM] [Info] Number of positive: 4673, number of negative: 3455\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018488 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3570\n",
      "[LightGBM] [Info] Number of data points in the train set: 8128, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.574926 -> initscore=0.301979\n",
      "[LightGBM] [Info] Start training from score 0.301979\n",
      "[CV] END catboost__depth=4, catboost__iterations=500, catboost__learning_rate=0.01, lgbm__learning_rate=0.01, lgbm__n_estimators=500, lgbm__num_leaves=31, xgboost__learning_rate=0.01, xgboost__max_depth=6, xgboost__n_estimators=500; total time=  26.6s\n",
      "[CV] END catboost__depth=4, catboost__iterations=500, catboost__learning_rate=0.01, lgbm__learning_rate=0.01, lgbm__n_estimators=500, lgbm__num_leaves=31, xgboost__learning_rate=0.01, xgboost__max_depth=6, xgboost__n_estimators=500; total time=  27.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/susan/BTP/.venv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [10:41:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4673, number of negative: 3455\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002626 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3570\n",
      "[LightGBM] [Info] Number of data points in the train set: 8128, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.574926 -> initscore=0.301979\n",
      "[LightGBM] [Info] Start training from score 0.301979\n",
      "[CV] END catboost__depth=4, catboost__iterations=500, catboost__learning_rate=0.01, lgbm__learning_rate=0.01, lgbm__n_estimators=500, lgbm__num_leaves=31, xgboost__learning_rate=0.01, xgboost__max_depth=6, xgboost__n_estimators=500; total time=  29.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/susan/BTP/.venv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [10:41:54] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END catboost__depth=4, catboost__iterations=500, catboost__learning_rate=0.01, lgbm__learning_rate=0.01, lgbm__n_estimators=500, lgbm__num_leaves=31, xgboost__learning_rate=0.01, xgboost__max_depth=9, xgboost__n_estimators=100; total time=  27.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/susan/BTP/.venv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [10:41:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4673, number of negative: 3455\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002636 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3570\n",
      "[LightGBM] [Info] Number of data points in the train set: 8128, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.574926 -> initscore=0.301979\n",
      "[LightGBM] [Info] Start training from score 0.301979\n",
      "[CV] END catboost__depth=4, catboost__iterations=500, catboost__learning_rate=0.01, lgbm__learning_rate=0.01, lgbm__n_estimators=500, lgbm__num_leaves=31, xgboost__learning_rate=0.01, xgboost__max_depth=9, xgboost__n_estimators=100; total time=  28.1s\n",
      "[CV] END catboost__depth=4, catboost__iterations=500, catboost__learning_rate=0.01, lgbm__learning_rate=0.01, lgbm__n_estimators=500, lgbm__num_leaves=31, xgboost__learning_rate=0.01, xgboost__max_depth=9, xgboost__n_estimators=100; total time=  27.7s\n",
      "[CV] END catboost__depth=4, catboost__iterations=500, catboost__learning_rate=0.01, lgbm__learning_rate=0.01, lgbm__n_estimators=500, lgbm__num_leaves=31, xgboost__learning_rate=0.01, xgboost__max_depth=6, xgboost__n_estimators=500; total time=  33.8s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 18\u001b[0m\n\u001b[1;32m     15\u001b[0m grid_search \u001b[38;5;241m=\u001b[39m GridSearchCV(estimator\u001b[38;5;241m=\u001b[39mvoting_model, param_grid\u001b[38;5;241m=\u001b[39mparam_grid, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Fit GridSearchCV\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m \u001b[43mgrid_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# Output best parameters and best score\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest Parameters:\u001b[39m\u001b[38;5;124m\"\u001b[39m, grid_search\u001b[38;5;241m.\u001b[39mbest_params_)\n",
      "File \u001b[0;32m~/BTP/.venv/lib/python3.12/site-packages/sklearn/base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1471\u001b[0m     )\n\u001b[1;32m   1472\u001b[0m ):\n\u001b[0;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/BTP/.venv/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1018\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m   1013\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m   1014\u001b[0m     )\n\u001b[1;32m   1016\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m-> 1018\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1020\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m   1021\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m   1022\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/BTP/.venv/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1572\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1570\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1571\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1572\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/BTP/.venv/lib/python3.12/site-packages/sklearn/model_selection/_search.py:964\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    956\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    957\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    958\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    959\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    960\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[1;32m    961\u001b[0m         )\n\u001b[1;32m    962\u001b[0m     )\n\u001b[0;32m--> 964\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    965\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    966\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    967\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    968\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    969\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    970\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    971\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    972\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    973\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    974\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    975\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    976\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    977\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    978\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplitter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    979\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    980\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    982\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    983\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    984\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    985\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    986\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    987\u001b[0m     )\n",
      "File \u001b[0;32m~/BTP/.venv/lib/python3.12/site-packages/sklearn/utils/parallel.py:74\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     69\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     70\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     71\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     73\u001b[0m )\n\u001b[0;32m---> 74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/BTP/.venv/lib/python3.12/site-packages/joblib/parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[1;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/BTP/.venv/lib/python3.12/site-packages/joblib/parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[1;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/BTP/.venv/lib/python3.12/site-packages/joblib/parallel.py:1762\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m   1760\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[1;32m   1761\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1763\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[1;32m   1766\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[1;32m   1767\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Cell 4: Define the parameter grid for GridSearchCV\n",
    "param_grid = {\n",
    "    'catboost__iterations': [500, 1000],\n",
    "    'catboost__learning_rate': [0.01, 0.05, 0.1],\n",
    "    'catboost__depth': [4, 6, 8],\n",
    "    'xgboost__n_estimators': [100, 500],\n",
    "    'xgboost__learning_rate': [0.01, 0.1],\n",
    "    'xgboost__max_depth': [3, 6, 9],\n",
    "    'lgbm__n_estimators': [100, 500],\n",
    "    'lgbm__learning_rate': [0.01, 0.1],\n",
    "    'lgbm__num_leaves': [31, 63]\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=voting_model, param_grid=param_grid, cv=5, n_jobs=-1, verbose=2)\n",
    "\n",
    "# Fit GridSearchCV\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Output best parameters and best score\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best Score:\", grid_search.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9894\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Make predictions and evaluate the best model from GridSearchCV\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
